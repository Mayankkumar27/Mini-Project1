Mini-Project-2: Introduction to LLMs & Generative AI

ðŸ“Š Sentiment Analysis using NLP & Word Embeddings

ðŸ“Œ Project Overview

This project is developed as part of Mini Project 2 â€“ Fundamentals of NLP: Text Cleaning & Vectorization in the course Introduction to Large Language Models and Generative AI.

The objective is to create an automated sentiment analysis pipeline for e-commerce product reviews. The system categorizes customer feedback into Positive, Negative, or Neutral sentiments.
It highlights the role of text preprocessing, vectorization techniques (BoW, Word2Vec, GloVe), and dataset preparation for downstream machine learning tasks.

â¸»

ðŸš€ Problem Statement

An e-commerce platform specializing in electronic gadgets is experiencing:
	â€¢	A 200% increase in its customer base over the past three years
	â€¢	A 25% rise in feedback volume

Manually analyzing thousands of reviews has become infeasible.
The absence of an automated system can lead to:
	â€¢	Higher customer churn
	â€¢	Damage to brand reputation
	â€¢	Potential financial setbacks

To address this, the company requires an AI-based sentiment classification solution.

â¸»

ðŸ“‚ Dataset Details
	â€¢	Product ID â†’ Unique product identifier
	â€¢	Review Text â†’ Customer feedback/comments
	â€¢	Sentiment Label â†’ Positive / Negative / Neutral
	â€¢	Dataset Size â†’ 1007 rows Ã— 3 columns

â¸»

ðŸ› ï¸ Methodology

ðŸ”¹ 1. Text Preprocessing
	â€¢	Removal of punctuation & special symbols
	â€¢	Conversion of text to lowercase
	â€¢	Stripping redundant whitespaces
	â€¢	Stopword removal using NLTK
	â€¢	Stemming (Porter Stemmer)
	â€¢	Lemmatization (WordNet Lemmatizer)

ðŸ”¹ 2. Exploratory Data Analysis (EDA)
	â€¢	Visualization of sentiment distribution (class imbalance observed)
	â€¢	Word frequency plots to capture common patterns

ðŸ”¹ 3. Feature Engineering & Vectorization
	â€¢	Bag of Words (BoW) representation
	â€¢	Word2Vec embeddings (CBOW & Skip-gram)
	â€¢	GloVe embeddings for semantic context

ðŸ”¹ 4. Model Evaluation Metrics
	â€¢	Macro F1-Score (handles imbalance better than accuracy)
	â€¢	Precision, Recall per sentiment class
	â€¢	Confusion Matrix for error analysis

â¸»

ðŸ“ˆ Key Findings
	â€¢	Dataset is imbalanced, with ~85% reviews labeled as Positive.
	â€¢	Macro F1-Score provides a more reliable metric than accuracy.
	â€¢	Word embeddings (Word2Vec, GloVe) outperform BoW in capturing semantic relationships.

â¸»

ðŸ—ï¸ Technology Stack
	â€¢	Python â†’ Pandas, NumPy, Scikit-learn
	â€¢	NLTK & Gensim â†’ Preprocessing and embeddings
	â€¢	Matplotlib & Seaborn â†’ Data visualization
	â€¢	Google Colab â†’ Development & execution environment

â¸»

ðŸ“Š Workflow

flowchart TD
    A[Raw Review Data] --> B[Text Preprocessing]
    B --> C[EDA & Visualization]
    C --> D[Vectorization Techniques]
    D --> E[Embeddings: Word2Vec & GloVe]
    E --> F[Model Training & Evaluation]
    F --> G[Future Scope: Deployment]

